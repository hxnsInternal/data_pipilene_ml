# Configuración de la etapa de ingestión de datos
ingest:
  files:
    - path: "data/input/prints.json"  # Ruta al archivo de impresiones en formato JSON
      format: "json"                  # Especifica el formato del archivo (JSON)
    - path: "data/input/taps.json"    # Ruta al archivo de clics en formato JSON
      format: "json"                  # Especifica el formato del archivo (JSON)
    - path: "data/input/pays.csv"     # Ruta al archivo de pagos en formato CSV
      format: "csv"                   # Especifica el formato del archivo (CSV)
      options:                        # Opciones adicionales para la lectura de CSV
        header: true                  # Indica si el archivo CSV contiene un encabezado
        inferSchema: true             # Permite a PySpark inferir automáticamente el esquema del archivo

# Configuración de la etapa de transformación de datos
transform:
  time_frame_on_days: 21              # Definición del marco temporal en días para análisis de datos

# Configuración de la etapa de carga de datos procesados
load:
  output_path: "data/output"          # Directorio de salida donde se almacenarán los datos procesados
  partitions: 1                       # Número de particiones para el archivo de salida
  format: "csv"                       # Formato de salida (CSV)

# Configuración de los logs de la aplicación
logging:
  level: "INFO"                       # Nivel de detalle de los logs (INFO, DEBUG, ERROR, etc.)
  file: "logs/pipeline.log"           # Archivo donde se almacenarán los logs de la ejecución
